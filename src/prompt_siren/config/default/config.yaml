# Default Configuration
# This file contains a comprehensive set of defaults for all configuration pieces.

defaults:
  # @package _global_
  - _self_
  - override hydra/job_logging: none # Disable Hydra's default logging to file
  - override hydra/hydra_logging: none # Disable Hydra's internal logging to file
  # Note: launcher configuration should be in your config/hydra/launcher/ directory
  # Default is BasicLauncher (runs jobs sequentially on local machine)

# =============================================================================
# HYDRA CONFIGURATION
# =============================================================================
# Disable Hydra's default output directory creation since we use our own
# job-based persistence system
hydra:
  output_subdir: null # Don't create .hydra subdirectory
  job:
    chdir: false # Don't change working directory
  run:
    dir: . # Use current directory instead of outputs/
  sweep:
    # For multirun sweeps, put Hydra/Submitit logs alongside our job outputs
    # This keeps SLURM logs and experimental results organized together
    dir: ${output.jobs_dir}/multirun/${now:%Y-%m-%d_%H-%M-%S}
    subdir: ${hydra.job.num} # Subdirectory for each job in a sweep

# =============================================================================
# EXPERIMENT METADATA
# =============================================================================
name: "default_experiment"

# =============================================================================
# AGENT CONFIGURATION
# =============================================================================
agent:
  type: plain # Available types: plain
  config:
    model: azure:gpt-5-nano # Model identifier
    model_settings: {} # Additional model-specific settings
    tool_result_serialization_mode: json # How to serialize tool outputs ("json" or "yaml")

# =============================================================================
# EXECUTION CONFIGURATION
# =============================================================================
execution:
  concurrency: 1 # Number of concurrent tasks (1-4 recommended)
  n_runs_per_task: 1 # Number of runs per task (use with resume for multiple runs)

# =============================================================================
# TASK SELECTION
# =============================================================================
task_ids: null # Task IDs to run (null = all tasks appropriate for mode)

# Alternative task selection configurations:
#
# For all tasks (default):
# task_ids: null
#
# For specific task couples (format: "benign_id:malicious_id"):
# task_ids: ["user_task_1:injection_task_1", "user_task_2:injection_task_2"]
#
# For specific individual tasks:
# task_ids: ["user_task_1", "user_task_2"]
#
# Note: Execution mode determines what "all tasks" means:
#   - Benign mode: all unique benign tasks
#   - Attack mode: all task couples

# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================
output:
  jobs_dir: "jobs" # Directory for job outputs

# =============================================================================
# OBSERVABILITY & TELEMETRY
# =============================================================================
telemetry:
  trace_console: true # Enable console tracing
  otel_endpoint: "http://localhost:6006/v1/traces" # OpenTelemetry endpoint

# =============================================================================
# USAGE LIMITS
# =============================================================================
# Set to null for no limits
usage_limits:
  request_limit: null # Maximum number of requests
  # tool_calls_limit: null # Maximum tool calls (null = no limit) -- Commented out because it is not enforced.
  input_tokens_limit: null # Maximum input tokens (null = no limit)
  output_tokens_limit: null # Maximum output tokens (null = no limit)
  total_tokens_limit: null # Maximum total tokens
  count_tokens_before_request: false # Count tokens before making request

# =============================================================================
# SLURM CONFIGURATION (for --slurm flag)
# =============================================================================
# These settings are used when submitting jobs with --slurm flag.
# They can be overridden via CLI: --slurm-partition, --slurm-time
slurm:
  partition: learnfair # SLURM partition
  time_minutes: 240 # Time limit in minutes
  gpus_per_node: 0 # Number of GPUs (0 for CPU-only jobs)
  cpus_per_task: 4 # CPUs per task
  mem_gb: 32 # Memory in GB
  # constraint: null # Optional constraint (e.g., "volta32gb")
  # additional_parameters: {} # Extra submitit parameters

# =============================================================================
# COMMON EXPERIMENT CONFIGURATIONS
# =============================================================================
#
# 1. LOCAL EXPERIMENT:
#    prompt-siren run benign +dataset=agentdojo-workspace
#
# 2. SLURM EXPERIMENT:
#    prompt-siren run attack --slurm +dataset=agentdojo-workspace +attack=mini-goat
#
# 3. SLURM SWEEP (parameter combinations run as separate jobs):
#    prompt-siren run attack --slurm +dataset=agentdojo-workspace +attack=mini-goat \
#      agent.config.model=azure:gpt-4,azure:gpt-5 '+run_id=range(10)'
#
# 4. RESUME FAILED SWEEP ON SLURM:
#    prompt-siren jobs resume-sweep -s 2026-01-31_17-01-04 --slurm
#
# See docs/slurm.md for more details.
